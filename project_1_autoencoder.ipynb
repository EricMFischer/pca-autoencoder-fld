{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here now\n",
      "loading autoencoder\n",
      "done loading autoencoder\n",
      "Loss for Reconstructing Appearance of Warped Test Images:  0.006820490350946784\n",
      "Loss for Reconstructing Geometry of Test Landmarks:  0.0007941091025713831\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status check: \n",
      "length, shape of APP_LATENT_Z:  2402 (2402,)\n",
      "length, shape of GEO_LATENT_Z:  2402 (2402,)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages')\n",
    "import cv2\n",
    "import numpy as np\n",
    "import argparse\n",
    "import skimage\n",
    "import scipy.io as sio\n",
    "import import_ipynb\n",
    "import glob\n",
    "import math\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from mywarper import warp\n",
    "from skimage import io, transform\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from torch.autograd import Variable\n",
    "\n",
    "parser = argparse.ArgumentParser(description='stat231_project1')\n",
    "parser.add_argument('--epochs', type=int, default=300)\n",
    "parser.add_argument('--batch_size', type=int, default=100)\n",
    "parser.add_argument('--seed', type=int, default=12345)\n",
    "parser.add_argument('--device', type=int, default=0)\n",
    "parser.add_argument('--image_dir', type=str, default='./images/')\n",
    "parser.add_argument('--landmark_dir', type=str, default='./landmarks/')\n",
    "parser.add_argument('--male_img_dir', type=str, default='./male_images/')\n",
    "parser.add_argument('--female_img_dir', type=str, default='./female_images/')\n",
    "parser.add_argument('--male_landmark', type=str, default='./male_landmarks/')\n",
    "parser.add_argument('--female_landmark', type=str, default='./female_landmarks/')\n",
    "parser.add_argument('--path', type=str, default='./results/model/')\n",
    "parser.add_argument('--log', type=str, default='./results/log/')\n",
    "parser.add_argument('--appear_lr', type=float, default=7e-4)\n",
    "parser.add_argument('--landmark_lr', type=float, default=1e-4)\n",
    "\n",
    "# Read Dataset\n",
    "class data_reader(object):\n",
    "    def __init__(self, root_dir, file_str_len, origin_name, file_format):\n",
    "        self.root_dir = root_dir\n",
    "        self.file_str_len = file_str_len\n",
    "        self.origin_name = origin_name\n",
    "        self.file_format = file_format\n",
    "\n",
    "    def read(self, split, read_type):\n",
    "        files_len = len([name for name in os.listdir(self.root_dir) \n",
    "                        if os.path.isfile(os.path.join(self.root_dir, name))])\n",
    "        counter = 0\n",
    "        idx = counter\n",
    "        dataset = []\n",
    "        train_dataset = []\n",
    "        test_dataset = []\n",
    "        while counter < files_len:\n",
    "            name = self.origin_name + str(idx)\n",
    "            if len(name) > self.file_str_len:\n",
    "                name = name[len(name)-self.file_str_len:]\n",
    "            try:\n",
    "                if read_type == 'image':\n",
    "                    data = io.imread(self.root_dir + name + self.file_format)\n",
    "                elif read_type == 'landmark':\n",
    "                    mat_data = sio.loadmat(self.root_dir + name + self.file_format)\n",
    "\n",
    "                    data = mat_data['lms']\n",
    "                dataset.append(data)\n",
    "                counter += 1\n",
    "            except FileNotFoundError:\n",
    "                pass\n",
    "            idx += 1\n",
    "        train_dataset = dataset[:split]\n",
    "        test_dataset = dataset[split:]\n",
    "        return train_dataset, test_dataset\n",
    "\n",
    "# Construct Dataset\n",
    "class ImgToTensor(object):\n",
    "    def __call__(self, sample):\n",
    "        sample = sample.transpose((2, 0, 1))\n",
    "        return torch.tensor(sample, dtype=torch.float32)/255\n",
    "\n",
    "class LandmarkToTensor(object):\n",
    "    def __call__(self, sample):\n",
    "        return torch.tensor(sample, dtype=torch.float32)/128\n",
    "\n",
    "class dataset_constructor(Dataset):\n",
    "    def __init__(self, dataset, transform=None):\n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample_data = self.dataset[idx]\n",
    "        if self.transform:\n",
    "            sample_data = self.transform(sample_data)\n",
    "        return sample_data\n",
    "\n",
    "'''\n",
    "CONV layer: computes output of neurons connected to local regions in input,\n",
    "each layer computing a dot product between its weights and the small region\n",
    "to which it is connected in the input volume. This may result in volume such\n",
    "as [32x32x12] if we decided to use 12 filters.\n",
    "ReLU layer: applies an element-wise activation function, such as the max(0,x)\n",
    "thresholding at zero. This leaves the size of the volume unchanged ([32x32x12]).\n",
    "POOL layer: performs a downsampling operation along the spatial dimensions (width, height),\n",
    "resulting in volume such as [16x16x12].\n",
    "FC (fully-connected) layer: computes the class scores, resulting in volume of size [1x1x10],\n",
    "in which each of the 10 numbers corresponds to a class score, e.g. among the 10 categories of CIFAR-10.\n",
    "As with ordinary Neural Networks, each neuron in this layer is connected to all numbers in previous volume.\n",
    "\n",
    "CONV/FC: perform transformations based on activations of input volume and weights and biases of neurons.\n",
    "Parameters are trained with gradient descent so that class scores are consistent with labels in training set.\n",
    "ReLU/POOL: implement a fixed function\n",
    "CONV/FC/POOL: may have hyperparameters (ReLU does not)\n",
    "'''\n",
    "\n",
    "APP_LATENT_Z = []\n",
    "GEO_LATENT_Z = []\n",
    "\n",
    "# Convolutional architecture, reconstructs and generates 2-d face images\n",
    "class appearance_autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(appearance_autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            # Applies a 2D convolution over input signal composed of several input planes\n",
    "            # params: (in_channels, out_channels, kernel_size, stride=1, padding=0, ...)\n",
    "            nn.Conv2d(3, 16, kernel_size=3, stride=2, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(128 * 8 * 8, 50),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            # De-Conv in PyTorch: ConvTranspose2d\n",
    "            nn.ConvTranspose2d(50, 128, kernel_size=8, stride=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.ConvTranspose2d(32, 16, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.ConvTranspose2d(16 ,3, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        latent_z = self.fc1(x.view(-1, 128 * 8 * 8))\n",
    "        APP_LATENT_Z.append(latent_z)\n",
    "        x_recon = self.decoder(latent_z.view(-1, 50, 1, 1))\n",
    "        return x_recon\n",
    "\n",
    "# Fully-connected architecture, reconstructs and generates landmarks\n",
    "class landmark_autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(landmark_autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            # Applies a linear transformation to the incoming data: y = x*A' + b\n",
    "            nn.Linear(68 * 2, 100),\n",
    "            # Applies element-wise LeakyReLU(x) = max(0,x) + negative_slope * min(0,x)\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(100, 10),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(10, 100),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(100, 68 * 2),\n",
    "            # Applies element-wise Sigmoid(x) = 1 / (1 + exp(−x))\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        latent_z = self.encoder(x)\n",
    "        GEO_LATENT_Z.append(latent_z)\n",
    "        x_recon = self.decoder(latent_z)\n",
    "        return x_recon\n",
    "\n",
    "class autoencoder(object):\n",
    "    def __init__(self, appear_lr, landmark_lr, use_cuda):\n",
    "        self.appear_model = appearance_autoencoder()\n",
    "        self.landmark_model = landmark_autoencoder()\n",
    "        self.use_cuda = use_cuda\n",
    "        if use_cuda:\n",
    "            self.appear_model.cuda()\n",
    "            self.landmark_model.cuda()\n",
    "        self.criterion = nn.MSELoss() # MSELoss loss = (x_n − y_n)^2\n",
    "        self.appear_optim = optim.Adam(self.appear_model.parameters(), lr=appear_lr)\n",
    "        self.landmark_optim = optim.Adam(self.landmark_model.parameters(), lr=landmark_lr)\n",
    "        \n",
    "    def train_appear_model(self, epochs, trainloader):\n",
    "        self.appear_model.train()\n",
    "        recon = []\n",
    "        final_loss = 0\n",
    "        for epoch in range(0, epochs):\n",
    "            final_epoch = epoch == epochs - 1\n",
    "            training_loss = 0\n",
    "            for batch in trainloader:\n",
    "                self.appear_optim.zero_grad()\n",
    "                batch_recon = self.appear_model(batch)\n",
    "                if final_epoch:\n",
    "                    recon.append(batch_recon)\n",
    "                loss = self.criterion(batch_recon, batch)\n",
    "                loss.backward()\n",
    "                # Updates parameters, can be called once gradients are computed with backward()\n",
    "                self.appear_optim.step()\n",
    "                training_loss += loss.item()\n",
    "            if final_epoch: \n",
    "                final_loss = training_loss\n",
    "            print('Training Appearance Epoch: {}, Loss: {:.6f}'.format(epoch, training_loss / len(trainloader)))\n",
    "        return recon, final_loss, self\n",
    "\n",
    "    def train_landmark_model(self, epochs, trainloader):\n",
    "        self.landmark_model.train()\n",
    "        recon = []\n",
    "        final_loss = 0\n",
    "        for epoch in range(0, epochs):\n",
    "            final_epoch = epoch == epochs - 1\n",
    "            training_loss = 0\n",
    "            for batch in trainloader:\n",
    "                self.landmark_optim.zero_grad()\n",
    "                batch_recon = self.landmark_model(batch)\n",
    "                if final_epoch:\n",
    "                    recon.append(batch_recon)\n",
    "                loss = self.criterion(batch_recon, batch)\n",
    "                loss.backward()\n",
    "                self.landmark_optim.step()\n",
    "                training_loss += loss.item()\n",
    "            if final_epoch:\n",
    "                final_loss = training_loss\n",
    "            print('Training Landmark Epoch: {}, Loss: {:.6f}'.format(epoch, training_loss / len(trainloader)))\n",
    "        return recon, final_loss\n",
    "        \n",
    "    def test_appear_model(self, testloader):\n",
    "        self.appear_model.eval()\n",
    "        recon = []\n",
    "        training_loss = 0\n",
    "        for batch in testloader:\n",
    "            batch_recon = self.appear_model(batch)\n",
    "            recon.append(batch_recon)\n",
    "            loss = self.criterion(batch_recon, batch)\n",
    "            training_loss += loss.item()\n",
    "        return recon, training_loss\n",
    "    \n",
    "    def test_landmark_model(self, testloader):\n",
    "        self.landmark_model.eval()\n",
    "        recon = []\n",
    "        training_loss = 0\n",
    "        for batch in testloader:\n",
    "            batch_recon = self.landmark_model(batch)\n",
    "            recon.append(batch_recon)\n",
    "            loss = self.criterion(batch_recon, batch)\n",
    "            training_loss += loss.item()\n",
    "        return recon, training_loss\n",
    "    \n",
    "def train_landmark_model(ae, landmark_trainloader):\n",
    "    landmark_train_recon, landmark_train_final_loss = ae.train_landmark_model(args.epochs, landmark_trainloader)\n",
    "    f = open('landmark_train_final_loss.pckl', 'wb')\n",
    "    pickle.dump(landmark_train_final_loss, f)\n",
    "    f.close()\n",
    "#     f = open('landmark_train_final_loss.pckl', 'rb')\n",
    "#     landmark_train_final_loss = pickle.load(f)\n",
    "#     f.close()\n",
    "    \n",
    "    print('Final Epoch Loss for Training Landmark Model: ', landmark_train_final_loss)\n",
    "    return landmark_train_final_loss\n",
    "\n",
    "def train_appear_model_with_warped_imgs(ae, images_train_warped):\n",
    "    warped_face_trainset = dataset_constructor(images_train_warped, transform=transforms.Compose([\n",
    "                                                                    ImgToTensor()]))\n",
    "    warped_face_trainloader = torch.utils.data.DataLoader(warped_face_trainset, \\\n",
    "                                                    batch_size=args.batch_size, \\\n",
    "                                                    shuffle=True, \\\n",
    "                                                    num_workers=2)\n",
    "    images_train_recon, images_train_final_loss, ae = ae.train_appear_model(args.epochs, warped_face_trainloader)\n",
    "    f = open('images_train_final_loss.pckl', 'wb')\n",
    "    pickle.dump(images_train_final_loss, f)\n",
    "    f.close()\n",
    "#     f = open('images_train_final_loss.pckl', 'rb')\n",
    "#     images_train_final_loss = pickle.load(f)\n",
    "#     f.close()\n",
    "\n",
    "    print('images_train_recon: ', np.shape(images_train_recon), torch.max(images_train_recon[0]), torch.min(images_train_recon[0]))\n",
    "    print('Final Epoch Loss for Training Appearance Model (with warped images): ', images_train_final_loss)\n",
    "    return images_train_final_loss, ae\n",
    "\n",
    "def recon_appear_warped_test_imgs(ae, images_test_warped):\n",
    "    warped_face_testset = dataset_constructor(images_test_warped, transform=transforms.Compose([\n",
    "                                                                    ImgToTensor()]))\n",
    "    warped_face_testloader = torch.utils.data.DataLoader(warped_face_testset, \\\n",
    "                                                    batch_size=args.batch_size, \\\n",
    "                                                    shuffle=True, \\\n",
    "                                                    num_workers=2)\n",
    "    face_testset_recon_appear, face_testset_training_loss = ae.test_appear_model(warped_face_testloader)\n",
    "    print('Loss for Reconstructing Appearance of Warped Test Images: ', face_testset_training_loss)\n",
    "    return face_testset_recon_appear\n",
    "\n",
    "def recon_geometry_test_landmarks(ae, landmark_testloader):\n",
    "    landmark_test_recon, landmark_test_training_loss = ae.test_landmark_model(landmark_testloader)\n",
    "    print('Loss for Reconstructing Geometry of Test Landmarks: ', landmark_test_training_loss)\n",
    "    return landmark_test_recon\n",
    "\n",
    "def calc_mean(A):\n",
    "    A_sum = np.zeros(np.shape(A[0]))\n",
    "    for item in A:\n",
    "        A_sum += item\n",
    "    return A_sum / len(A)\n",
    "\n",
    "def warp_imgs_to_mean(imgs, landmark_train, landmark_mean):\n",
    "    warped_imgs = []\n",
    "    for i, img in enumerate(imgs):\n",
    "        warped_img = warp(img, landmark_train[i], landmark_mean)\n",
    "        warped_imgs.append(warped_img)\n",
    "    return warped_imgs\n",
    "\n",
    "def warp_imgs_back(face_testset_recon_appear, landmark_mean, landmark_test_recon):\n",
    "    unwarped_imgs = [] \n",
    "    for batch_i, batch in enumerate(face_testset_recon_appear):\n",
    "        for i, img in enumerate(batch):\n",
    "            img = img.permute(1, 2, 0).detach().numpy()\n",
    "            recon_landmark = np.reshape(landmark_test_recon[batch_i][i].detach().numpy(), (68, 2))\n",
    "            unwarped_img = warp(img, landmark_mean, recon_landmark)\n",
    "            unwarped_imgs.append(unwarped_img)\n",
    "    return unwarped_imgs\n",
    "\n",
    "def disp_recon_imgs(recon_imgs, orig_imgs):\n",
    "    f, axes = plt.subplots(4, 5)\n",
    "    for i, img in enumerate(recon_imgs):\n",
    "        img = img.clip(min=0, max=1)\n",
    "        row = math.floor(i / 5)\n",
    "        axes[row, i % 5].imshow(img)\n",
    "    plt.show()\n",
    "    \n",
    "    f, axes = plt.subplots(4, 5)\n",
    "    for i, img in enumerate(orig_imgs):\n",
    "        row = math.floor(i / 5)\n",
    "        axes[row, i % 5].imshow(img)\n",
    "    plt.show()\n",
    "\n",
    "def reshape_landmarks(landmarks):\n",
    "    results = []\n",
    "    for landmark in landmarks:\n",
    "        flat = np.asarray(landmark).flatten()\n",
    "        results.append(flat)\n",
    "    return results\n",
    "\n",
    "def run_autoencoder():\n",
    "    face_trainset = dataset_constructor(images_train, transform=transforms.Compose([\n",
    "                                                                    ImgToTensor()]))\n",
    "    face_testset = dataset_constructor(images_test, transform=transforms.Compose([\n",
    "                                                                    ImgToTensor()]))\n",
    "    face_trainloader = torch.utils.data.DataLoader(face_trainset, \\\n",
    "                                                    batch_size=args.batch_size, \\\n",
    "                                                    shuffle=True, \\\n",
    "                                                    num_workers=2)\n",
    "    face_testloader = torch.utils.data.DataLoader(face_testset, \\\n",
    "                                                    batch_size=args.batch_size, \\\n",
    "                                                    shuffle=False, \\\n",
    "                                                    num_workers=2)\n",
    "    \n",
    "    landmark_train_mod = reshape_landmarks(landmark_train)\n",
    "    landmark_trainset = dataset_constructor(landmark_train_mod, transform=transforms.Compose([\n",
    "                                                                    LandmarkToTensor()]))\n",
    "    landmark_test_mod = reshape_landmarks(landmark_test)\n",
    "    landmark_testset = dataset_constructor(landmark_test_mod, transform=transforms.Compose([\n",
    "                                                                    LandmarkToTensor()]))\n",
    "    landmark_trainloader = torch.utils.data.DataLoader(landmark_trainset, \\\n",
    "                                                        batch_size=args.batch_size, \\\n",
    "                                                        shuffle=True, \\\n",
    "                                                        num_workers=2)\n",
    "    landmark_testloader = torch.utils.data.DataLoader(landmark_testset, \\\n",
    "                                                        batch_size=args.batch_size, \\\n",
    "                                                        shuffle=False, \\\n",
    "                                                        num_workers=2)\n",
    "\n",
    "    # ----------------------- Autoencoder: Question 1 ------------------------\n",
    "    # Train a landmark model with training landmarks\n",
    "    # ae = autoencoder(args.appear_lr, args.landmark_lr, 0)\n",
    "    # landmark_train_final_loss = train_landmark_model(ae, landmark_trainloader)\n",
    "    \n",
    "    print('here now')\n",
    "    # Warp training images into the mean position\n",
    "    landmark_mean = calc_mean(landmark_train)\n",
    "    images_train_warped = warp_imgs_to_mean(images_train, landmark_train, landmark_mean)\n",
    "\n",
    "    # Train appearance model with warped images\n",
    "    # images_train_final_loss, ae = train_appear_model_with_warped_imgs(ae, images_train_warped)\n",
    "#     f = open('autoencoder.pckl', 'wb')\n",
    "#     pickle.dump(ae, f)\n",
    "#     f.close()\n",
    "    print('loading autoencoder')\n",
    "    f = open('autoencoder.pckl', 'rb')\n",
    "    ae = pickle.load(f)\n",
    "    f.close()\n",
    "    print('done loading autoencoder')\n",
    "\n",
    "    # Warp test images into the mean position\n",
    "    images_test_warped = warp_imgs_to_mean(images_test, landmark_test, landmark_mean)\n",
    "    \n",
    "    # Reconstruct appearance of warped test images using appear_model(images_test_warped)\n",
    "    face_testset_recon_appear = recon_appear_warped_test_imgs(ae, images_test_warped)\n",
    "    \n",
    "    # Reconstruct geometry of test landmarks using landmark_model(test_landmarks)\n",
    "    landmark_test_recon = recon_geometry_test_landmarks(ae, landmark_testloader)\n",
    "    \n",
    "    # Warp the warped test images back from the mean position to reconstructed test landmarks\n",
    "    recon_faces = warp_imgs_back(face_testset_recon_appear, landmark_mean, landmark_test_recon)\n",
    "\n",
    "    # Plot 20 reconstructed faces and their corresponding original faces\n",
    "    disp_recon_imgs(recon_faces[:20], images_test[:20])\n",
    "    \n",
    "    # Save latent z variables\n",
    "#     f = open('app_latent_z.pckl', 'wb')\n",
    "#     pickle.dump(APP_LATENT_Z, f)\n",
    "#     f.close()\n",
    "#     f = open('geo_latent_z.pckl', 'wb')\n",
    "#     pickle.dump(GEO_LATENT_Z, f)\n",
    "#     f.close()\n",
    "    f = open('app_latent_z.pckl', 'rb')\n",
    "    APP_LATENT_Z = pickle.load(f)\n",
    "    f.close()\n",
    "    f = open('geo_latent_z.pckl', 'rb')\n",
    "    GEO_LATENT_Z = pickle.load(f)\n",
    "    f.close()\n",
    "\n",
    "    print('Status check: ')\n",
    "    print('length, shape of APP_LATENT_Z: ', len(APP_LATENT_Z), np.shape(APP_LATENT_Z))\n",
    "    print('length, shape of GEO_LATENT_Z: ', len(GEO_LATENT_Z), np.shape(GEO_LATENT_Z))\n",
    "    \n",
    "    # ----------------------- Autoencoder: Question 2 ------------------------\n",
    "\n",
    "def main():\n",
    "    run_autoencoder()\n",
    "\n",
    "args = parser.parse_args(args=[])\n",
    "args.cuda = torch.cuda.is_available()\n",
    "torch.cuda.set_device(-1) # was 0\n",
    "\n",
    "if not os.path.exists(args.path):\n",
    "    os.makedirs(args.path)\n",
    "if not os.path.exists(args.log):\n",
    "    os.makedirs(args.log)\n",
    "\n",
    "if args.cuda:\n",
    "    torch.cuda.manual_seed(args.seed)\n",
    "\n",
    "face_images_reader = data_reader(args.image_dir, 6, '000000', '.jpg')\n",
    "images_train, images_test = face_images_reader.read(split=800, \\\n",
    "                                                                read_type='image')\n",
    "\n",
    "face_landmark_reader = data_reader(args.landmark_dir, 6, '000000', '.mat')\n",
    "landmark_train, landmark_test = face_landmark_reader.read(split=800, \\\n",
    "                                                                read_type='landmark')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
